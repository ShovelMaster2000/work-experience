{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLlCaIirtxoQ"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1.\n",
        "Обучить полносвязную модель на MNIST"
      ],
      "metadata": {
        "id": "Ud1FvLQwt9RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.MNIST('.', download=True)"
      ],
      "metadata": {
        "id": "KtX_QbYZuGTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.data.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iICC65BpuGWH",
        "outputId": "b0d641f7-61eb-4fba-d20a-1fb76351829a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(dataset.data[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "b-NkSZRavxhJ",
        "outputId": "192f9fc7-d372-486a-bed6-7f5aefc6f900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создание архитектуры модели\n",
        "class LinearModel(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.1):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, hidden_dim)  # слой 1\n",
        "    self.linear2 = nn.Linear(hidden_dim, hidden_dim)  # cлой 2\n",
        "    self.linear3 = nn.Linear(hidden_dim, output_dim)  # cлой 3\n",
        "    self.do1 = nn.Dropout(dropout_p)  # зануление нейронов между 1 и 2 слоем\n",
        "    self.do2 = nn.Dropout(dropout_p)  # зануление нейронов между 2 и 3 слоем\n",
        "    self.activation = nn.ReLU()  # ф-ия активации\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.do1(self.activation(self.linear1(x)))\n",
        "    x = self.do2(self.activation(self.linear2(x)))\n",
        "    return self.linear3(x)"
      ],
      "metadata": {
        "id": "KOjUbR_1wRJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ия обработки батчей\n",
        "def collate_fn(data: list):\n",
        "  pics = []\n",
        "  target = []\n",
        "  for item in data:\n",
        "    pics.append(numpy.array(item[0]))\n",
        "    target.append(item[1])\n",
        "  pics = torch.from_numpy(numpy.array(pics)).float() / 255\n",
        "  target = torch.from_numpy(numpy.array(target))\n",
        "\n",
        "  return {\n",
        "      'data': pics.view(pics.size(0), -1), \n",
        "      'target': target\n",
        "      }"
      ],
      "metadata": {
        "id": "7KXWx-JOwUm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# задание гиперпараметров\n",
        "input_dim = 28 * 28  # 784\n",
        "hidden_dim = 256 + 128\n",
        "output_dim = 10\n",
        "device_id = -1\n",
        "device = 'cpu' if device_id == -1 else f'cuda:{device_id}'\n",
        "n_epochs = 10\n",
        "batch_size = 128 + 172"
      ],
      "metadata": {
        "id": "zwDXrQJZwUsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearModel(input_dim, hidden_dim, output_dim).to(device)\n",
        "optim_rms = torch.optim.RMSprop(model.parameters())  # формируем оптимизатор\n",
        "optim_adam = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.CrossEntropyLoss()  # определение ф-ии потерь"
      ],
      "metadata": {
        "id": "j-5BHxYxwUpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# процесс обучения\n",
        "for epoch in range(n_epochs):\n",
        "  dataloader = DataLoader(dataset, \n",
        "                          batch_size, \n",
        "                          shuffle=True, \n",
        "                          collate_fn=collate_fn,\n",
        "                          drop_last=True,  # выкидывает последний батч если он меньше заданного размера\n",
        "                          )\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    optim_rms.zero_grad()\n",
        "    predict = model(batch['data'].to(device))\n",
        "    loss = loss_func(predict, batch['target'].to(device).long())\n",
        "    loss.backward() # расчитывает градиенты\n",
        "    optim_rms.step()\n",
        "    if i % 200 == 0:\n",
        "      print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "  torch.save(model.state_dict(), f'./chkpt_{epoch}.pth')  # сохранение чекпоинта модели"
      ],
      "metadata": {
        "id": "2TIL5KBh_KH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1500aa40-7e35-4c45-d426-87b2f137e056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.303877115249634\n",
            "epoch: 1, step: 0, loss: 0.16502483189105988\n",
            "epoch: 2, step: 0, loss: 0.1364763081073761\n",
            "epoch: 3, step: 0, loss: 0.16865627467632294\n",
            "epoch: 4, step: 0, loss: 0.2164524644613266\n",
            "epoch: 5, step: 0, loss: 0.12518177926540375\n",
            "epoch: 6, step: 0, loss: 0.12044809013605118\n",
            "epoch: 7, step: 0, loss: 0.062001921236515045\n",
            "epoch: 8, step: 0, loss: 0.1187746524810791\n",
            "epoch: 9, step: 0, loss: 0.06152720004320145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# процесс обучения\n",
        "for epoch in range(n_epochs):\n",
        "  dataloader = DataLoader(dataset, \n",
        "                          batch_size, \n",
        "                          shuffle=True, \n",
        "                          collate_fn=collate_fn,\n",
        "                          drop_last=True,  # выкидывает последний батч если он меньше заданного размера\n",
        "                          )\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    optim_adam.zero_grad()\n",
        "    predict = model(batch['data'].to(device))\n",
        "    loss = loss_func(predict, batch['target'].to(device).long())\n",
        "    loss.backward() # расчитывает градиенты\n",
        "    optim_adam.step()\n",
        "    if i % 200 == 0:\n",
        "      print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "  torch.save(model.state_dict(), f'./chkpt_{epoch}.pth')  # сохранение чекпоинта модели"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed62bec-aa6a-43ed-ad29-61412614e21b",
        "id": "Vjw8cF08DlL-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 0.05258622765541077\n",
            "epoch: 1, step: 0, loss: 0.027443373575806618\n",
            "epoch: 2, step: 0, loss: 0.04527699202299118\n",
            "epoch: 3, step: 0, loss: 0.0401105135679245\n",
            "epoch: 4, step: 0, loss: 0.02968071587383747\n",
            "epoch: 5, step: 0, loss: 0.01127178966999054\n",
            "epoch: 6, step: 0, loss: 0.006737405434250832\n",
            "epoch: 7, step: 0, loss: 0.019145546481013298\n",
            "epoch: 8, step: 0, loss: 0.007881798781454563\n",
            "epoch: 9, step: 0, loss: 0.013595941476523876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** оптимизатор Adam в сравнении с RMSProp показывает показывает ошибку обучения на порядок ниже"
      ],
      "metadata": {
        "id": "B94GYtfzBEYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2.\n",
        "Обучить глубокую сверточную сеть на MNIST"
      ],
      "metadata": {
        "id": "8c0ij6CSuGno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# создание архитектуры модели\n",
        "class ConvModel(nn.Module):\n",
        "  def __init__(self, input_ch, hidden_ch, output_dim, dropout_p=0.1):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(input_ch, hidden_ch, \n",
        "                           kernel_size=5, padding=2, stride=2)  # свертка (уменш.в 2раза)\n",
        "    self.bn1 = nn.BatchNorm2d(hidden_ch) # нормализация\n",
        "    self.conv2 = nn.Conv2d(hidden_ch, hidden_ch,\n",
        "                           kernel_size=3, padding=1)  # свертка\n",
        "    self.bn2 = nn.BatchNorm2d(hidden_ch)\n",
        "    self.conv3 = nn.Conv2d(hidden_ch, 2,\n",
        "                           kernel_size=3, padding=1)  # свертка\n",
        "    self.bn3 = nn.BatchNorm2d(2)\n",
        "    self.linear3 = nn.Linear(2 * 14 * 14, output_dim)  # cлой классификации\n",
        "    self.do1 = nn.Dropout(dropout_p)  # зануление нейронов между 1 и 2 слоем\n",
        "    self.do2 = nn.Dropout(dropout_p)  # зануление нейронов между 2 и 3 слоем\n",
        "    self.activation = nn.ReLU()  # ф-ия активации\n",
        "     \n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.do1(self.activation(self.bn1(self.conv1(x))))\n",
        "    x = self.do2(self.activation(self.bn2(self.conv2(x))))\n",
        "    x = self.activation(self.bn3(self.conv3(x)))  # B * 12 * 12\n",
        "    \n",
        "    return self.linear3(x.view(x.size(0), -1))"
      ],
      "metadata": {
        "id": "rvycWGp5rbk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ф-ия обработки батчей\n",
        "def collate_fn_conv(data: list):\n",
        "  pics = []\n",
        "  target = []\n",
        "  for item in data:\n",
        "    pics.append(numpy.array(item[0]))\n",
        "    target.append(item[1])\n",
        "  pics = torch.from_numpy(numpy.array(pics)).float() / 255\n",
        "  target = torch.from_numpy(numpy.array(target))\n",
        "\n",
        "  return {\n",
        "      'data': pics.unsqueeze(1), \n",
        "      'target': target.long()\n",
        "      }"
      ],
      "metadata": {
        "id": "Bi21xNtGudWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# задание гиперпараметров\n",
        "input_ch = 1  # 784\n",
        "hidden_ch = 128\n",
        "output_dim = 10\n",
        "device_id = 0\n",
        "device = 'cpu' if device_id == -1 else f'cuda:{device_id}'\n",
        "n_epochs = 10\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "TuIZW3nvudWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = ConvModel(input_ch, hidden_ch, output_dim).to(device)\n",
        "optim = torch.optim.Adam(model_conv.parameters())  # формируем оптимизатор\n",
        "loss_func = nn.CrossEntropyLoss()  # определение ф-ии потерь"
      ],
      "metadata": {
        "id": "8QnFdGvcudWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# процесс обучения\n",
        "for epoch in range(n_epochs):\n",
        "  dataloader = DataLoader(dataset, \n",
        "                          batch_size, \n",
        "                          shuffle=True, \n",
        "                          collate_fn=collate_fn_conv,\n",
        "                          drop_last=True,  # выкидывает последний батч если он меьше заданного размера\n",
        "                          )\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    optim.zero_grad()\n",
        "    predict = model_conv(batch['data'].to(device))\n",
        "    loss = loss_func(predict, batch['target'].to(device))\n",
        "    loss.backward() # расчитывает градиенты\n",
        "    optim.step()\n",
        "    if i % 400 == 0:\n",
        "      print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "  torch.save(model_conv.state_dict(), f'./chkpt_conv_{epoch}.pth')  # сохранение чекпойинта модели"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a14356c-589d-4db0-c09b-f1255d6e4944",
        "id": "QdWSCz0sudWl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 0.02051735110580921\n",
            "epoch: 0, step: 400, loss: 0.05650608241558075\n",
            "epoch: 1, step: 0, loss: 0.022455455735325813\n",
            "epoch: 1, step: 400, loss: 0.017734207212924957\n",
            "epoch: 2, step: 0, loss: 0.00926903821527958\n",
            "epoch: 2, step: 400, loss: 0.003949418198317289\n",
            "epoch: 3, step: 0, loss: 0.02523891068994999\n",
            "epoch: 3, step: 400, loss: 0.004886065609753132\n",
            "epoch: 4, step: 0, loss: 0.010927299968898296\n",
            "epoch: 4, step: 400, loss: 0.0038823499344289303\n",
            "epoch: 5, step: 0, loss: 0.0013564538676291704\n",
            "epoch: 5, step: 400, loss: 0.010924956761300564\n",
            "epoch: 6, step: 0, loss: 0.01026804931461811\n",
            "epoch: 6, step: 400, loss: 0.012806103564798832\n",
            "epoch: 7, step: 0, loss: 0.007155256811529398\n",
            "epoch: 7, step: 400, loss: 0.009901256300508976\n",
            "epoch: 8, step: 0, loss: 0.003924274817109108\n",
            "epoch: 8, step: 400, loss: 0.005915656685829163\n",
            "epoch: 9, step: 0, loss: 0.010234196670353413\n",
            "epoch: 9, step: 400, loss: 0.011571325361728668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создание архитектуры модели (использование пулинга)\n",
        "class ConvModelV2(nn.Module):\n",
        "  def __init__(self, input_ch, hidden_ch, output_dim, dropout_p=0.1):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(input_ch, hidden_ch, \n",
        "                           kernel_size=5, padding=2, stride=1)  # свертка (уменш.в 2раза)\n",
        "    self.pool1 = nn.MaxPool2d(2,2)\n",
        "    self.bn1 = nn.BatchNorm2d(hidden_ch) # нормализация\n",
        "    self.conv2 = nn.Conv2d(hidden_ch, hidden_ch,\n",
        "                           kernel_size=3, padding=1)  # свертка\n",
        "    self.bn2 = nn.BatchNorm2d(hidden_ch)\n",
        "    self.conv3 = nn.Conv2d(hidden_ch, 2,\n",
        "                           kernel_size=3, padding=1)  # свертка\n",
        "    self.bn3 = nn.BatchNorm2d(2)\n",
        "    self.linear3 = nn.Linear(2 * 14 * 14, output_dim)  # cлой классификации\n",
        "    self.do1 = nn.Dropout(dropout_p)  # зануление нейронов между 1 и 2 слоем\n",
        "    self.do2 = nn.Dropout(dropout_p)  # зануление нейронов между 2 и 3 слоем\n",
        "    self.activation = nn.ReLU()  # ф-ия активации\n",
        "     \n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.do1(self.activation(self.bn1(self.pool1(self.conv1(x)))))\n",
        "    x = self.do2(self.activation(self.bn2(self.conv2(x))))\n",
        "    x = self.activation(self.bn3(self.conv3(x)))  # B * 12 * 12\n",
        "    \n",
        "    return self.linear3(x.view(x.size(0), -1))"
      ],
      "metadata": {
        "id": "1v6_HqB1Hecq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv_v2 = ConvModelV2(input_ch, hidden_ch, output_dim).to(device)\n",
        "optim = torch.optim.Adam(model_conv_v2.parameters())  # формируем оптимизатор\n",
        "loss_func = nn.CrossEntropyLoss()  # определение ф-ии потерь"
      ],
      "metadata": {
        "id": "seREIJduHecu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# процесс обучения\n",
        "for epoch in range(n_epochs):\n",
        "  dataloader = DataLoader(dataset, \n",
        "                          batch_size, \n",
        "                          shuffle=True, \n",
        "                          collate_fn=collate_fn_conv,\n",
        "                          drop_last=True,  # выкидывает последний батч если он меьше заданного размера\n",
        "                          )\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    optim.zero_grad()\n",
        "    predict = model_conv_v2(batch['data'].to(device))\n",
        "    loss = loss_func(predict, batch['target'].to(device))\n",
        "    loss.backward() # расчитывает градиенты\n",
        "    optim.step()\n",
        "    if i % 400 == 0:\n",
        "      print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "  torch.save(model_conv_v2.state_dict(), f'./chkpt_conv_{epoch}.pth')  # сохранение чекпойинта модели"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drehpaogHecv",
        "outputId": "2d56d35b-6957-4209-aa7f-50ba4605312f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.371856212615967\n",
            "epoch: 0, step: 400, loss: 0.05620186775922775\n",
            "epoch: 1, step: 0, loss: 0.06407012045383453\n",
            "epoch: 1, step: 400, loss: 0.0648491159081459\n",
            "epoch: 2, step: 0, loss: 0.034042321145534515\n",
            "epoch: 2, step: 400, loss: 0.05642253905534744\n",
            "epoch: 3, step: 0, loss: 0.008731827139854431\n",
            "epoch: 3, step: 400, loss: 0.021205900236964226\n",
            "epoch: 4, step: 0, loss: 0.049343291670084\n",
            "epoch: 4, step: 400, loss: 0.015877239406108856\n",
            "epoch: 5, step: 0, loss: 0.007207996211946011\n",
            "epoch: 5, step: 400, loss: 0.04810795187950134\n",
            "epoch: 6, step: 0, loss: 0.010293238796293736\n",
            "epoch: 6, step: 400, loss: 0.015594851225614548\n",
            "epoch: 7, step: 0, loss: 0.017290085554122925\n",
            "epoch: 7, step: 400, loss: 0.00932107213884592\n",
            "epoch: 8, step: 0, loss: 0.005736505147069693\n",
            "epoch: 8, step: 400, loss: 0.006375493947416544\n",
            "epoch: 9, step: 0, loss: 0.007236498408019543\n",
            "epoch: 9, step: 400, loss: 0.015202701091766357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** использование пулинга по максимальному значению для уменьшения размерности вместо уменьшения размерности с помощью свертки дает более позднюю сходимость модели"
      ],
      "metadata": {
        "id": "2v13ZCgAJoq7"
      }
    }
  ]
}